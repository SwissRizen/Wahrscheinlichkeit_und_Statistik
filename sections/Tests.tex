\section{Tests}
\begin{subbox}{}
	Die \tbf{Null Hypothesis} \(H_0\) und die \tbf{Alternative Hypothesis} \(H_A\) sind zwei Teilmengen \(\Theta_0 \subseteq \Theta, \Theta_A \subseteq \Theta\) wobei \(\Theta_0 \cap \Theta_A = \varnothing\). 

	Falls keine explizite Alternative Hypothesis spezifiziert ist, so hat man $\Theta_A = \Theta \setminus \Theta_0$. 

	Eine Hypothese heisst \textit{einfach}, falls die Teilmenge aus einem einzelnen Wert besteht; sonst \textit{zusammengesetzt}.
\end{subbox}

\begin{mainbox}{Definition Test}
	Ein Test ist ein Tupel \((T,K)\), wobei \(T\) eine \(RV\) der Form \(T=t(X_1, \ldots, X_n)\) und \(K \subseteq \R\) eine deterministische Teilmenge von \(\R\) ist. Wir nennen \(T\) die \textit{statistic} und \(K\) den \textit{critical region} oder kritischen Bereich.
\end{mainbox}

Wir wollen nun anhand der Daten \((X_1(\omega), \ldots, X_n(\omega))\) entscheiden, ob die Null Hypothesis akzeptiert oder verworfen wird. Zuerst berechnen wir die statistic \(T(\omega) = t(X_1(\omega), \ldots, X_n(\omega))\) und gehen dann wie folgt vor:
\begin{itemize}
	\item Die Hypothese \(H_0\) wird \textit{verworfen}, falls \(T(\omega) \in K\).
	\item Die Hypothese \(H_0\) wird \textit{akzeptiert}, falls \(T(\omega) \notin K\).
\end{itemize}
\begin{subbox}{}
	Ein \tbf{Fehler 1. Art} ist, wenn \(H_0\) fälschlicherweise verworfen wird, obwohl sie richtig ist.
	\[\P_\theta(T \in K), \quad \theta \in \Theta_0\]
	\noindent Ein \tbf{Fehler 2. Art} ist, wenn \(H_0\) fälschlicherweise akzeptiert wird, obwohl sie falsch ist.
	\[\P_\theta(T\notin K) = 1 - \P_\theta(T \in K), \quad \theta \in \Theta_A\]
\end{subbox}
\textbf{Bemerkung: } Da $T$ eine RV und somit bezüglich dem Mass $\P_\theta: \F \to [0,1]$ messbar ist, gilt $\{T \in K\} \in \F$ und somit ist $\P_\theta(T \in K)$ well-defined. 
\subsection{Significance Level und Power}
Ein Test hat Significance Level \(a \in [0,1]\) falls
\[\forall \theta \in \Theta_0 \quad \P_\theta(T \in K) \le a\]
Es ist meist unser primäres Ziel, die Fehler 1. Art zu minimieren.

Das sekundäre Ziel ist, Fehler 2. Art zu vermeiden. Hierfür definieren wir die Power eines Tests als Funktion:
\[\beta : \Theta_A \mapsto [0,1], \quad \theta \mapsto \P_\theta(T \in K)\]
Zu beachten ist, dass eine kleine Wahrscheinlichkeit für einen Fehler 2. Art einem \textit{grossen} \(\beta\) entspricht.

\subsection{Konstruktion von Tests}
Wir nehmen an, dass \(X_1, \ldots, X_n\) discrete oder gemeinsam continuous unter \(\P_{\theta_0}\) und \(\P_{\theta_A}\) sind, wobei \(\Theta_0 \cap \Theta_A = \emptyset\) einfach sind (\(\theta_0 \in \Theta_0 \land \theta_A \in \Theta_A\)).

\noindent Der Likelihood-Ratio ist somit well-defined:
\[R(x_1, \ldots, x_n) = \frac{L(x_1,\ldots, x_n;\theta_A)}{L(x_1, \ldots, x_n;\theta_0)}\]
(Falls \(L(x_1, \ldots, x_n; \theta_0) = 0\) setzen wir \(R(x_1, \ldots, x_n) = +\infty\).) 

Für zusammengesetzte $\Theta_0$ und $\Theta_A$ können wir den verallg. Likelihood-Ratio definieren:
\[R(x_1, ..., x_n) := \frac{\sup_{\theta \in \Theta_A}L(x_1, \dots, x_n; \theta)}{\sup_{\theta \in \Theta_0}L(x_1, \dots, x_n; \theta)}\]


Wenn \(R \gg 1\), so gilt \(H_A > H_0\) und analog \(R \ll 1 \implies H_A < H_0\).

\begin{subbox}{}
	Der \tbf{Likelihood-Ratio-Test (LQ-Test)} mit Parameter \(c \ge 0\) ist definiert durch:
	\[T = R(X_1, \ldots, X_n) \quad \text{und} \quad K = (c, \infty]\]
\end{subbox}
\textbf{Neyman-Pearson-Lemma}

Der LQ-Test ist optimal, da jeder andere Test mit kleinerem (oder gleichem) Significance Level auch eine kleinere (oder gleiche) Power hat.

\subsection{Häufige Fälle}
\subsubsection*{\texorpdfstring{Normalverteilt - \(\mu\) unbekannt, \(\sigma^2\) bekannt (z-Test)}{Normalverteilt - μ unbekannt, σ² bekannt (z-Test)}}
Unbiaseder Estimator: \(\overline{X}_n = \frac{1}{n} \sum_{i=1}^n X_i\)\\
Distribution unter \(\P_\theta: \frac{\overline{X}_n - \theta_0}{\sqrt{\sigma^2/n}} \sim \mathcal{N}(0,1)\)
\begin{enumerate}
	\item Modell \(X_1, \ldots, X_n \sim \mathcal{N}(\theta, \sigma^2)\) iid. unter \(\P_\theta\)
	\item Hypothesen \(H_0 : \theta = \theta_0\) und \(H_A : \theta > \theta_0\), \(H_A : \theta < \theta_0\) (einseitig) oder \(H_A : \theta \ne \theta_0\) (zweiseitig)
	\item Test \(T = \frac{\overline{X}_n - \mu}{\sqrt{\sigma^2/n}} \sim \mathcal{N}(0,1)\) unter \(\P_{\theta_0}\)
	\item critical region \(K_{>} = (c_{>}, \infty)\), \(K_{<} = (-\infty, -c_{<})\) oder \(K_{\neq} = (-\infty, -c_{\neq}) \ \cup \ (c_{\neq}, \infty)\)
	\item \textbf{Fall 1} \(\alpha = \P_{\theta_0}(T \in K_>) = \P_{\theta_0}(T > c_>)\)\\
	\textbf{Fall 2} \(\alpha = \P_{\theta_0}(T \in K_<) = \P_{\theta_0}(T < -c_<) = 1 - \P_{\theta_0}(T \leq c_<)\)\\
	\textbf{Fall 3} \(\alpha = \P_{\theta_0}(T \in K_{\neq}) = \P_{\theta_0}(T < -c_{\neq}) + \P_{\theta_0}(T > c_{\neq}) = \P_{\theta_0}(T < -c_{\neq}) + 1 - \P_{\theta_0}(T \leq c_{\neq})\)
\end{enumerate}

\subsubsection*{\texorpdfstring{Normalverteilt - \(\mu\), \(\sigma^2\) unbekannt (t-Test)}{Normalverteilt - μ, σ² unbekannt (t-Test)}}
Wir definieren \(\vec{\theta} = (\mu, \sigma^2)\) und den Variance-Estimator \(S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \overline{X}_n)^2\).
\begin{enumerate}
	\item Modell \(X_1, \ldots, X_n \sim \mathcal{N}(\theta, \sigma^2)\) iid. unter \(\P_{\vec{\theta}}\)
	\item Hypothesen: $\Theta_0 = \{\mu_0\} \times (0, \infty)$, für die Alternative Hypothesis gibt es wieder die drei Fälle mit $\mu_A > \mu_0$, $\mu_A < \mu_0$ und $\mu_A \neq \mu_0$.
	\item statistic \(T = \frac{\overline{X}_n - \mu_0}{\sqrt{S^2/n}} \sim t_{n-1}\)
	\item Verewerfungsbereich: \(K_{>}\), \(K_{<}\) oder \(K_{\neq}\)
	\item Für Significance Level $\alpha$, können wir die kritischen Werte als $c_{>} = t_{n-1, 1-\alpha}, c_{<} = t_{n-1, 1- \alpha}$ und $c_{\neq} = t_{n-1, 1- \frac{\alpha}{2}}$ wählen.
	Hierbei bezeichnen wir mit $t_{m, \gamma}$, das $\gamma$-Quantil einer $t_m$-Distribution (i.e. derjenige Wert $z = t_{m, \gamma}$, so dass für $X \sim t_m$ $\P(X \leq z) = \gamma$ gilt).
\end{enumerate}
\subsubsection*{Gepaarter Zweistichprobentest: $\mu_X, \mu_Y$, gleiche Variance $\sigma^2$}
Sei $X_1, ..., X_n$ iid. $\sim \mathcal{N}(\mu_X, \sigma^2)$ und $Y_1, \dots, Y_n$ iid. $\sim \mathcal{N}(\mu_Y, \sigma^2)$, wobei $X_i, Y_i$ independent.

Dann ist für $Z_i := X_i - Y_i$ die RV $Z_1, \dots, Z_n$ iid. $\sim \mathcal{N}(\mu_X -\mu_Y, 2\sigma^2)$. 

Für bekanntes $\sigma$ können wir auf den $Z_i$ dann den z-Test ausführen, wenn unbekannt dann der t-Test.
\subsubsection*{Ungepaarter Zweistichprobentest: $\mu_X, \mu_Y$, gleiche Variance $\sigma^2$}
Sei $X_1, ..., X_n$ iid. $\sim \mathcal{N}(\mu_X, \sigma^2)$ und $Y_1, \dots, Y_m$ iid. $\sim \mathcal{N}(\mu_Y, \sigma^2)$, wobei $m \neq n$, $X_1, ..., X_n$ und  $Y_1, ..., Y_m$ independent.
\begin{enumerate}
	\item \textbf{$\sigma^2$ bekannt.} Dann haben wir folgende statistic
	\[T := \frac{(\overline{X}_n -\overline{Y}_m) - (\mu_X - \mu_Y)}{\sigma\sqrt{\frac{1}{n}+\frac{1}{m}}} \sim \mathcal{N}(0,1) \text{ unter jedem }\P_{\theta}\]
	Mit dem können wir dann den z-Test ausführen.
	\item \textbf{$\sigma^2$ unbekannt.} Empirische Varianceen der einzelnen beiden Datensätzen
	\[S^2_X := \frac{1}{n-1}\sum_{i=1}^n(X_i - \overline{X}_n)^2 \text{ und } S^2_Y := \frac{1}{m-1}\sum_{j=1}^m(Y_j - \overline{Y}_m)^2\]
	kombinieren wir zu einer empirischen Variance
	\[S^2 := \frac{1}{m+n-2}((n-1)S^2_X + (m-1)S_Y^2)\]
	Daraus die statistic
	\[T := \frac{(\overline{X}_n -\overline{Y}_m) - (\mu_X - \mu_Y)}{S\sqrt{\frac{1}{n}+\frac{1}{m}}} \sim t_{m+n-2} \text{ unter jedem }\P_{\theta}\]
	In diesem Fall machen wir damit ein t-Test.
\end{enumerate}
\subsection{p-Value}
Sei \(T = t(X_1, \ldots, X_n)\) eine statistic und \((T,K_t)_{t\ge 0}\) eine Familie von Tests.

\begin{subbox}{Geordnete statistic}
	Eine Familie von Tests heisst geordnet bzgl. \(T\) falls \(K_t \subset \R\) und \(s \le t \implies K_t \subseteq K_s\). Beispiele:
	\begin{itemize}
		\item \(K_t = (t, \infty)\) (rechtsseitiger Test)
		\item \(K_t = (-\infty, -t)\) (linksseitiger Test)
		\item \(K_t = (-\infty, -t) \cup (t, \infty)\) (beidseitiger Test)
	\end{itemize}
\end{subbox}

\begin{mainbox}{Definition p-Value}
	Sei \(H_0: \theta = \theta_0\) eine einfache Null Hypothesis. Sei \((T, K_t)_{t\ge 0}\) eine geordnete Familie von Tests. Der \(p\)-Wert ist definiert als RV \(G(\omega)\), wobei
	\[G: \Omega \mapsto [0,1], \quad G(\omega) = \P_{\theta_0}[T \in K_{t(X_1(\omega), ..., X_n(\omega))}]\]
\end{mainbox}
\textbf{Intuitiv: } Wenn wir den critical region mit dem realisierten Wert der statistic bestimmen würden; was wäre das Significance Level (i.e. Fehler 1. Art)?

Der \(p\)-Wert hat folgende Eigenschaften:
\begin{enumerate}
	\item Sei \(T\) continuous und \(K_t = (t, \infty)\). Dann ist der \(p\)-Wert unter \(\P_{\theta_0}\) auf \([0,1]\) gleichverteilt.
	\item Für einen \(p\)-Wert \(\gamma\) gilt, dass alle Tests mit Significance Level \(\alpha > \gamma\) die Null Hypothesis verwerfen.
\end{enumerate}

Insgesamt gilt also:
\[\text{kleiner } p\text{-Wert} \implies H_0 \text{ wird wahrscheinlich verworfen} \]

