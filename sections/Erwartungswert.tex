\section{Expected Value}
\begin{mainbox}{Expected Value - Discrete RV}
    Sei $X: \Omega \to \R$ eine discrete Random Variable, $W_X := X(\Omega)$ und $\phi: \R \to \R$ eine Abbildung. Falls die Summe well-defined ist, gilt: 
    $$\mathbb{E}(\phi(X)) := \sum_{x \in W_X} \phi(x) \cdot \P(X = x)$$
    Wenn $X: \Omega \to \N_0$, kann man auch den Expected Value als
    $$\mathbb{E}(X) = \sum_{n = 0}^{\infty}\P(X > n)$$
    schreiben.
\end{mainbox}
\begin{mainbox}{Expected Value - Continuous RV}
    Sei $X: \Omega \to \R$ eine continuouse Random Variable mit Density $f$. Sei $\phi: \R \to \R$ eine Abbildung, sodass $\phi(X)$ eine Random Variable ist. Dann gilt
    $$\mathbb{E}(\phi(X))= \int_{-\infty}^\infty \phi(x)f(x)\dx,$$
    solange das Integral well-defined ist.
    \\Sei $X$ eine continuouse RV mit $X \geq 0$ a.s., dann gilt:
    $$\E(X)=\int_0^\infty \P(X > x)\dx$$ 
\end{mainbox}

\subsection{Rechnen mit Expected Value}
\textbf{Linearity des Expected Values}: 

Seien $X, Y: \Omega \to \R$ RV mit $\lambda \in \R$, Falls die Expected Valuee well-defined sind, gilt:
$$\mathbb{E}(\lambda \cdot X + Y) = \lambda \cdot \mathbb{E}(X) + \mathbb{E}(Y)$$

Falls $X, Y$ \textbf{independent}, dann gilt auch:
$$\mathbb{E}(X \cdot Y) = \mathbb{E}(X) \cdot \mathbb{E}(Y)$$

Eine generellere Form wäre folgende Äquivalenz:\\
$X_1, X_2, ...,X_n$ independent
\\$\iff$
\\Für jede $\phi_1: \R \to \R, \ldots, \phi_n: \R \to \R$ stückweise continuous, bounded gilt
$$\E(\phi_1(X_1)\cdots\phi_n(X_n))=\E(\phi_1(X_1))\cdots\E(\phi_n(X_n))$$ 

\subsection{Inequalities}
\textbf{Monotonicity}
\\Seien $X, Y$ RV mit $X \leq Y$ a.s., dann gilt:
$$\E(X) \leq \E(Y)$$
\textbf{Markov Inequality}
\\Sei $X$ eine RV und ferner $g: X(\Omega) \to [0, +\infty)$ eine wachsende Funktion. Für jedes $c \in \R$ mit $g(c) > 0$ gilt dann
$$\P(X \geq c) \leq \frac{\E(g(X))}{g(c)}$$
\\\textit{Einfache Version:}
\\Sei $X$ eine RV mit $X\geq 0$ a.s., dann gilt für jedes $t > 0$:
$$\P(X \geq t) \leq \frac{\E(X)}{t}$$
\textbf{Chebyshev Inequality}
\\Sei $Y$ eine RV mit finiteer Variance. Für jedes $b > 0$ gilt dann
$$\P(|Y - \E(Y)| \geq b) \leq \frac{\text{Var}(Y)}{b^2}$$
\textbf{Jensen Inequality}
\\Sei $X$ eine RV und $\phi: \R \to \R$ eine konvexe Funktion, dann gilt:
$$\phi(\E(X)) \leq \E(\phi(X))$$

\subsection{Variance}
\begin{mainbox}{Variance}
    Sei $X$ eine RV, sodass $\E(X^2)<\infty$. Die \textbf{Variance} von $X$ ist definiert durch
    $$\Var(X) = \sigma_X^2 = \E((X - m)^2) = \E(X^2)-\E(X)^2$$
    wobei $m = \E(X)$. Dabei wird $\sigma_X$ als \textbf{Standardabweichung} von $X$ bezeichnet und beschreibt den Expected Value für die Distanz von $X$ zu $\E(X)$.
\end{mainbox}

\begin{enumerate}
    \item Sei $X$ ein RV, sodass $\E(X^2)<\infty$ und $a, b \in \R$:
    $$\Var(a\cdot X + b) = a^2 \cdot \Var(X)$$
    \item Seien $X_1, ..., X_n$ paarweise independent. Dann gilt
    $$\Var(X_1 + \ldots + X_n) = \Var(X_1)+\ldots +\Var(X_n)$$
\end{enumerate}

\begin{mainbox}{Covariance}
    Seien $X, Y$ RV mit $\E(X^2)<\infty, \E(Y^2) < \infty$. Wir definieren die \textbf{Covariance} zwischen $X$ und $Y$ durch
    $$\text{Cov}(X,Y) := \E(XY) - \E(X)\E(Y)$$
\end{mainbox}
\begin{enumerate}
    \item $\text{Cov}(X,X) = \Var(X)$
    \item $X, Y$ independent $\implies$ $\text{Cov}(X, Y) = 0$ (Die Umkehrung ist falsch!)
    \item $\Var(X+Y) = \Var(X) + \Var(Y) + 2\text{Cov}(X, Y)$
\end{enumerate}

\begin{subbox}{}
    \begin{itemize}
        \item Moment-generating Funktion: $M_X(t):=\E\left(e^{tX}\right).$ 
        \item Die $k$-te Ableitung ist das $k$-te Moment von $X$: $m_k := \E(X^k).$ 
        \item Das $k$-te zentrale Moment von $X$: $\mu_k := \E\left((X-\mu)^k\right).$ 
        \item Für $X$ continuous gilt deshalb $M_X(t) = \int_{-\infty}^\infty e^{tx} f(x) dx.$ 
        \item Das $k$-te empirische Moment der Realisierung $(x_{1\dots n}): \hat m_k(x_{1\dots n}) := \frac1n \sum_{i=1}^n x_i^k.$ 
    \end{itemize}
    
\end{subbox}

\subsection{Conditional Expected Value}
Sei $(\Omega, \A, \P)$ ein discreter Probability Space und $X:\Omega \to \R$ eine Random Variable. 

Für ein beliebiges $B \in A, \P(B) > 0$ definieren wir den \textbf{bedingten Expected Value} $X$ bedingt durch $B$ als
\begin{align*}
    \E(X \mid B) = \frac{\E(\mathds{1}_B X)}{\P(B)} &= \sum_{x \in X(\Omega)}x\P(X = x\mid B)\\ 
    &= \sum_{\omega \in \Omega}X(\omega)\P(\{\omega\}\mid B)
\end{align*}

\textbf{Conditional Expected Value als Random Variable}\\
Wir betrachten eine Partition $\mathcal{B} = (B_i)_{i \in I}$ von $\Omega$ ($B_i$ sind disjunkt und nichtleer, $I$ countable). 

Dann definieren wir die \textbf{Random Variable}
$$\E(X \mid \mathcal{B})(\omega) = \sum_{i \in I, \P(B_i > 0)} \E(X \mid B_i) \mathds{1}_{B_i}(\omega)$$ 
\begin{enumerate}
    \item \textbf{Intuition:} Die Information, die durch die Partition gegeben ist, ist dass eines der $B_i$ eintreten wird. Bei der Realisierung durch das Eintreten des Elementarereignisses $\omega$ wird $\E(X \mid \mathcal{B})$ zu dem $\E(X \mid B_i)$ realisiert, bei welchem $\omega \in B_i$.
    \item \textbf{Bemerkung:} Das $\mathcal{B}$ hat in der Vorlesung 2 verschiedene Bedeutungen. Es wird als Variable für sowohl die Borelsche $\sigma$-Algebra als auch die Partition von $\Omega$ verwendet.
\end{enumerate}

